{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sandersfeatures.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMPXLSVJEmmaaU9mBkhS2O2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmsaravanan99/Major-Project/blob/main/sandersfeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcUf-AkCL2xk"
      },
      "source": [
        "__init__.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAhzdGmIMsvo"
      },
      "source": [
        "import tweet_features, tweet_pca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0HsREG4M52W"
      },
      "source": [
        "tweetfeatures.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC1OHm6aM-33"
      },
      "source": [
        "\"\"\"\n",
        "@package tweet_features\n",
        "Convert tweet to feature vector.\n",
        "These routines help convert arbitrary tweets in to feature vectors.\n",
        "\"\"\"\n",
        "import numpy\n",
        "\n",
        "\n",
        "# search patterns for features\n",
        "testFeatures = \\\n",
        "    [('hasAddict',     (' addict',)), \\\n",
        "     ('hasAwesome',    ('awesome',)), \\\n",
        "     ('hasBroken',     ('broke',)), \\\n",
        "     ('hasBad',        (' bad',)), \\\n",
        "     ('hasBug',        (' bug',)), \\\n",
        "     ('hasCant',       ('cant','can\\'t')), \\\n",
        "     ('hasCrash',      ('crash',)), \\\n",
        "     ('hasCool',       ('cool',)), \\\n",
        "     ('hasDifficult',  ('difficult',)), \\\n",
        "     ('hasDisaster',   ('disaster',)), \\\n",
        "     ('hasDown',       (' down',)), \\\n",
        "     ('hasDont',       ('dont','don\\'t','do not','does not','doesn\\'t')), \\\n",
        "     ('hasEasy',       (' easy',)), \\\n",
        "     ('hasExclaim',    ('!',)), \\\n",
        "     ('hasExcite',     (' excite',)), \\\n",
        "     ('hasExpense',    ('expense','expensive')), \\\n",
        "     ('hasFail',       (' fail',)), \\\n",
        "     ('hasFast',       (' fast',)), \\\n",
        "     ('hasFix',        (' fix',)), \\\n",
        "     ('hasFree',       (' free',)), \\\n",
        "     ('hasFrowny',     (':(', '):')), \\\n",
        "     ('hasFuck',       ('fuck',)), \\\n",
        "     ('hasGood',       ('good','great')), \\\n",
        "     ('hasHappy',      (' happy',' happi')), \\\n",
        "     ('hasHate',       ('hate',)), \\\n",
        "     ('hasHeart',      ('heart', '<3')), \\\n",
        "     ('hasIssue',      (' issue',)), \\\n",
        "     ('hasIncredible', ('incredible',)), \\\n",
        "     ('hasInterest',   ('interest',)), \\\n",
        "     ('hasLike',       (' like',)), \\\n",
        "     ('hasLol',        (' lol',)), \\\n",
        "     ('hasLove',       ('love','loving')), \\\n",
        "     ('hasLose',       (' lose',)), \\\n",
        "     ('hasNeat',       ('neat',)), \\\n",
        "     ('hasNever',      (' never',)), \\\n",
        "     ('hasNice',       (' nice',)), \\\n",
        "     ('hasPoor',       ('poor',)), \\\n",
        "     ('hasPerfect',    ('perfect',)), \\\n",
        "     ('hasPlease',     ('please',)), \\\n",
        "     ('hasSerious',    ('serious',)), \\\n",
        "     ('hasShit',       ('shit',)), \\\n",
        "     ('hasSlow',       (' slow',)), \\\n",
        "     ('hasSmiley',     (':)', ':D', '(:')), \\\n",
        "     ('hasSuck',       ('suck',)), \\\n",
        "     ('hasTerrible',   ('terrible',)), \\\n",
        "     ('hasThanks',     ('thank',)), \\\n",
        "     ('hasTrouble',    ('trouble',)), \\\n",
        "     ('hasUnhappy',    ('unhapp',)), \\\n",
        "     ('hasWin',        (' win ','winner','winning')), \\\n",
        "     ('hasWinky',      (';)',)), \\\n",
        "     ('hasWow',        ('wow','omg')) ]\n",
        "\n",
        "\n",
        "def make_tweet_nparr( txt ):\n",
        "    \"\"\"\n",
        "    Extract tweet feature vector as NumPy array.\n",
        "    \"\"\"\n",
        "    # result storage\n",
        "    fvec = numpy.empty( len(testFeatures) )\n",
        "\n",
        "    # search for each feature\n",
        "    txtLow = ' ' + txt.lower() + ' '\n",
        "    for i in range( 0, len(testFeatures) ):\n",
        "\n",
        "        key = testFeatures[i][0]\n",
        "\n",
        "        fvec[i] = False\n",
        "        for tstr in testFeatures[i][1]:\n",
        "            fvec[i] = fvec[i] or (txtLow.find(tstr) != -1)\n",
        "\n",
        "    return fvec\n",
        "\n",
        "\n",
        "def make_tweet_dict( txt ):\n",
        "    \"\"\"\n",
        "    Extract tweet feature vector as dictionary.\n",
        "    \"\"\"\n",
        "    txtLow = ' ' + txt.lower() + ' '\n",
        "\n",
        "    # result storage\n",
        "    fvec = {}\n",
        "\n",
        "    # search for each feature\n",
        "    for test in testFeatures:\n",
        "\n",
        "        key = test[0]\n",
        "\n",
        "        fvec[key] = False;\n",
        "        for tstr in test[1]:\n",
        "            fvec[key] = fvec[key] or (txtLow.find(tstr) != -1)\n",
        "\n",
        "    return fvec\n",
        "\n",
        "\n",
        "def tweet_dict_to_nparr( dict ):\n",
        "    \"\"\"\n",
        "    Convert dictionary feature vector to numpy array\n",
        "    \"\"\"\n",
        "    fvec = numpy.empty( len(testFeatures) )\n",
        "\n",
        "    for i in range( 0, len(testFeatures) ):\n",
        "        fvec[i] = dict[ testFeatures[i][0] ]\n",
        "\n",
        "    return fvec\n",
        "\n",
        "\n",
        "def tweet_nparr_to_dict( nparr, use_standard_features=False ):\n",
        "    \"\"\"\n",
        "    Convert NumPy array to dictionary\n",
        "    \"\"\"\n",
        "    fvec = {}\n",
        "\n",
        "    if use_standard_features:\n",
        "        assert len(nparr) == len(testFeatures)\n",
        "        fvec = {}\n",
        "        for i in range( 0, len(nparr) ):\n",
        "            fvec[ testFeatures[i][0] ] = nparr[i]\n",
        "\n",
        "    else:\n",
        "        for i in range( 0, len(nparr) ):\n",
        "            fvec[ str(i) ] = nparr[i]\n",
        "\n",
        "    return fvec\n",
        "\n",
        "\n",
        "def is_zero_dict( dict ):\n",
        "    \"\"\"\n",
        "    Identifies empty feature vectors\n",
        "    \"\"\"\n",
        "    has_any_features = False\n",
        "    for key in dict:\n",
        "        has_any_features = has_any_features or dict[key]\n",
        "\n",
        "    return not has_any_features\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2omNcr-INSzV"
      },
      "source": [
        "tweet_pca.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viwRsFOlNe5B"
      },
      "source": [
        "\"\"\"\n",
        "@package tweet_pca\n",
        "PCT for dimensionality reduction.\n",
        "\"\"\"\n",
        "import mdp, numpy\n",
        "import tweet_features\n",
        "\n",
        "import pdb\n",
        "\n",
        "\n",
        "def tweet_pca_reduce( tweets_train, tweets_test, output_dim ):\n",
        "\n",
        "    # convert dictionary feature vecs to numpy array\n",
        "    print '--> Converting dictionaries to NumPy arrays'\n",
        "    train_arr = numpy.array( [tweet_features.tweet_dict_to_nparr(t) for \\\n",
        "                              (t,s) in tweets_train])\n",
        "\n",
        "    test_arr = numpy.array( [tweet_features.tweet_dict_to_nparr(t) for \\\n",
        "                             (t,s) in tweets_test])\n",
        "\n",
        "\n",
        "    # compute principle components over training set\n",
        "    print '--> Computing PCT'\n",
        "    pca_array = mdp.pca( train_arr.transpose(), \\\n",
        "                         svd=True, output_dim=output_dim )\n",
        "\n",
        "\n",
        "    # both train and test sets to PC space\n",
        "    print '--> Projecting feature vectors to PC space'\n",
        "\n",
        "    train_arr = numpy.dot( train_arr, pca_array )\n",
        "    test_arr  = numpy.dot( test_arr,  pca_array )\n",
        "\n",
        "\n",
        "    # convert projected vecs back to reduced dictionaries\n",
        "    print '--> Converting NumPy arrays to dictionaries'\n",
        "\n",
        "    reduced_train = \\\n",
        "        zip( [tweet_features.tweet_nparr_to_dict(v) for v in train_arr], \\\n",
        "             [s for (t,s) in tweets_train] )\n",
        "\n",
        "    reduced_test  = \\\n",
        "        zip( [tweet_features.tweet_nparr_to_dict(v) for v in test_arr], \\\n",
        "             [s for (t,s) in tweets_test])\n",
        "\n",
        "    return (reduced_train, reduced_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}