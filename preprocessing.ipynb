{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNyp+RjuSklhPQMInSK7s46",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmsaravanan99/Major-Project/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ5ApipeK1Rz"
      },
      "source": [
        "# This Python file uses the following encoding: "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3cVVsoIK76v"
      },
      "source": [
        "import re\n",
        "\n",
        "# Hashtags\n",
        "hash_regex = re.compile(r\"#(\\w+)\")\n",
        "def hash_repl(match):\n",
        "\treturn '__HASH_'+match.group(1).upper()\n",
        "\n",
        "# Handels\n",
        "hndl_regex = re.compile(r\"@(\\w+)\")\n",
        "def hndl_repl(match):\n",
        "\treturn '__HNDL'#_'+match.group(1).upper()\n",
        "\n",
        "# URLs\n",
        "url_regex = re.compile(r\"(http|https|ftp)://[a-zA-Z0-9\\./]+\")\n",
        "\n",
        "# Spliting by word boundaries\n",
        "word_bound_regex = re.compile(r\"\\W+\")\n",
        "\n",
        "# Repeating words like hurrrryyyyyy\n",
        "rpt_regex = re.compile(r\"(.)\\1{1,}\", re.IGNORECASE);\n",
        "def rpt_repl(match):\n",
        "\treturn match.group(1)+match.group(1)\n",
        "\n",
        "# Emoticons\n",
        "emoticons = \\\n",
        "\t[\t('__EMOT_SMILEY',\t[':-)', ':)', '(:', '(-:', ] )\t,\\\n",
        "\t\t('__EMOT_LAUGH',\t\t[':-D', ':D', 'X-D', 'XD', 'xD', ] )\t,\\\n",
        "\t\t('__EMOT_LOVE',\t\t['<3', ':\\*', ] )\t,\\\n",
        "\t\t('__EMOT_WINK',\t\t[';-)', ';)', ';-D', ';D', '(;', '(-;', ] )\t,\\\n",
        "\t\t('__EMOT_FROWN',\t\t[':-(', ':(', '(:', '(-:', ] )\t,\\\n",
        "\t\t('__EMOT_CRY',\t\t[':,(', ':\\'(', ':\"(', ':(('] )\t,\\\n",
        "\t]\n",
        "\n",
        "# Punctuations\n",
        "punctuations = \\\n",
        "\t[\t#('',\t\t['.', ] )\t,\\\n",
        "\t\t#('',\t\t[',', ] )\t,\\\n",
        "\t\t#('',\t\t['\\'', '\\\"', ] )\t,\\\n",
        "\t\t('__PUNC_EXCL',\t\t['!', '¡', ] )\t,\\\n",
        "\t\t('__PUNC_QUES',\t\t['?', '¿', ] )\t,\\\n",
        "\t\t('__PUNC_ELLP',\t\t['...', '…', ] )\t,\\\n",
        "\t\t#FIXME : MORE? http://en.wikipedia.org/wiki/Punctuation\n",
        "\t]\n",
        "\n",
        "#Printing functions for info\n",
        "def print_config(cfg):\n",
        "\tfor (x, arr) in cfg:\n",
        "\t\tprint x, '\\t',\n",
        "\t\tfor a in arr:\n",
        "\t\t\tprint a, '\\t',\n",
        "\t\tprint ''\n",
        "\n",
        "def print_emoticons():\n",
        "\tprint_config(emoticons)\n",
        "\n",
        "def print_punctuations():\n",
        "\tprint_config(punctuations)\n",
        "\n",
        "#For emoticon regexes\n",
        "def escape_paren(arr):\n",
        "\treturn [text.replace(')', '[)}\\]]').replace('(', '[({\\[]') for text in arr]\n",
        "\n",
        "def regex_union(arr):\n",
        "\treturn '(' + '|'.join( arr ) + ')'\n",
        "\n",
        "emoticons_regex = [ (repl, re.compile(regex_union(escape_paren(regx))) ) \\\n",
        "\t\t\t\t\tfor (repl, regx) in emoticons ]\n",
        "\n",
        "#For punctuation replacement\n",
        "def punctuations_repl(match):\n",
        "\ttext = match.group(0)\n",
        "\trepl = []\n",
        "\tfor (key, parr) in punctuations :\n",
        "\t\tfor punc in parr :\n",
        "\t\t\tif punc in text:\n",
        "\t\t\t\trepl.append(key)\n",
        "\tif( len(repl)>0 ) :\n",
        "\t\treturn ' '+' '.join(repl)+' '\n",
        "\telse :\n",
        "\t\treturn ' '\n",
        "\n",
        "def processHashtags( \ttext, subject='', query=[]):\n",
        "\treturn re.sub( hash_regex, hash_repl, text )\n",
        "\n",
        "def processHandles( \ttext, subject='', query=[]):\n",
        "\treturn re.sub( hndl_regex, hndl_repl, text )\n",
        "\n",
        "def processUrls( \t\ttext, subject='', query=[]):\n",
        "\treturn re.sub( url_regex, ' __URL ', text )\n",
        "\n",
        "def processEmoticons( \ttext, subject='', query=[]):\n",
        "\tfor (repl, regx) in emoticons_regex :\n",
        "\t\ttext = re.sub(regx, ' '+repl+' ', text)\n",
        "\treturn text\n",
        "\n",
        "def processPunctuations( text, subject='', query=[]):\n",
        "\treturn re.sub( word_bound_regex , punctuations_repl, text )\n",
        "\n",
        "def processRepeatings( \ttext, subject='', query=[]):\n",
        "\treturn re.sub( rpt_regex, rpt_repl, text )\n",
        "\n",
        "def processQueryTerm( \ttext, subject='', query=[]):\n",
        "\tquery_regex = \"|\".join([ re.escape(q) for q in query])\n",
        "\treturn re.sub( query_regex, '__QUER', text, flags=re.IGNORECASE )\n",
        "\n",
        "def countHandles(text):\n",
        "\treturn len( re.findall( hndl_regex, text) )\n",
        "def countHashtags(text):\n",
        "\treturn len( re.findall( hash_regex, text) )\n",
        "def countUrls(text):\n",
        "\treturn len( re.findall( url_regex, text) )\n",
        "def countEmoticons(text):\n",
        "\tcount = 0\n",
        "\tfor (repl, regx) in emoticons_regex :\n",
        "\t\tcount += len( re.findall( regx, text) )\n",
        "\treturn count\n",
        "\n",
        "#FIXME: preprocessing.preprocess()! wtf! will need to move.\n",
        "#FIXME: use process functions inside\n",
        "def processAll( \t\ttext, subject='', query=[]):\n",
        "\n",
        "\tif(len(query)>0):\n",
        "\t\tquery_regex = \"|\".join([ re.escape(q) for q in query])\n",
        "\t\ttext = re.sub( query_regex, '__QUER', text, flags=re.IGNORECASE )\n",
        "\n",
        "\ttext = re.sub( hash_regex, hash_repl, text )\n",
        "\ttext = re.sub( hndl_regex, hndl_repl, text )\n",
        "\ttext = re.sub( url_regex, ' __URL ', text )\n",
        "\n",
        "\tfor (repl, regx) in emoticons_regex :\n",
        "\t\ttext = re.sub(regx, ' '+repl+' ', text)\n",
        "\n",
        "\n",
        "\ttext = text.replace('\\'','')\n",
        "\t# FIXME: Jugad\n",
        "\n",
        "\ttext = re.sub( word_bound_regex , punctuations_repl, text )\n",
        "\ttext = re.sub( rpt_regex, rpt_repl, text )\n",
        "\n",
        "\treturn text\n",
        "\n",
        "#from time import time\n",
        "#import preprocessing, sanderstwitter02\n",
        "#tweets = sanderstwitter02.getTweetsRawData('sentiment.csv')\n",
        "#start = time()\n",
        "#procTweets = [ (preprocessing.preprocess(t),s) for (t,s) in tweets]\n",
        "#end = time()\n",
        "#end - start\n",
        "\n",
        "#uni = [ a if(a[0:2]=='__') else a.lower() for a in re.findall(r\"\\w+\", text) ]\n",
        "#bi  = nltk.bigrams(uni)\n",
        "#tri = nltk.trigrams(uni)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}